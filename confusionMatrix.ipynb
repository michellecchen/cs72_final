{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "confusionMatrix.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix Generation for Zero Shot Classification\n",
        "## Written by Leah Ryu for CS72 final, 22S\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "\n",
        "We need to test the effectiveness of the zero-shot classification we used to sort review sentences into topics. To do this, we'll generate a confusion matrix; this will require us to compare the true labels for each sentence to the predicted labels. We'll parse the predicted labels out of the confusion files, then prompt a user to input a true label for each sentence. Then we can print the confusion matrix."
      ],
      "metadata": {
        "id": "Pt6cD5vZcKWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "HavZtKxlonHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries needed to import files from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFD6OZI8oslz",
        "outputId": "0179772a-5de5-41a3-8f08-9e9a598ffee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open all the files we need: pos and neg data for the four companies\n",
        "f1 = open(\"/content/drive/MyDrive/compling_final/riotPosConfusion.txt\", 'r')\n",
        "riotPos = f1.readlines()\n",
        "\n",
        "f2 = open(\"/content/drive/MyDrive/compling_final/riotNegConfusion.txt\", 'r')\n",
        "riotNeg = f2.readlines()\n",
        "\n",
        "f3 = open(\"/content/drive/MyDrive/compling_final/sonyPosConfusion.txt\", 'r')\n",
        "sonyPos = f3.readlines()\n",
        "\n",
        "f4 = open(\"/content/drive/MyDrive/compling_final/sonyNegConfusion.txt\", 'r')\n",
        "sonyNeg = f4.readlines()\n",
        "\n",
        "f5 = open(\"/content/drive/MyDrive/compling_final/ubisoftPosConfusion.txt\", 'r')\n",
        "ubisoftPos = f5.readlines()\n",
        "\n",
        "f6 = open(\"/content/drive/MyDrive/compling_final/ubisoftNegConfusion.txt\", 'r')\n",
        "ubisoftNeg = f6.readlines()\n",
        "\n",
        "f7 = open(\"/content/drive/MyDrive/compling_final/activisionPosConfusion.txt\", 'r')\n",
        "activisionPos = f7.readlines()\n",
        "\n",
        "f8 = open(\"/content/drive/MyDrive/compling_final/activisionNegConfusion.txt\", 'r')\n",
        "activisionNeg = f8.readlines()"
      ],
      "metadata": {
        "id": "NXjzFV-3oxOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the files open, we'll parse the predicted values out of the zero shot classifiers."
      ],
      "metadata": {
        "id": "yetOsG_8tibZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the predicted values in a 1D array--order is important\n",
        "predictedLabels = []\n",
        "# Also store the sentences which were classified so that the user can later input\n",
        "# the true label.\n",
        "sentences = []\n",
        "\n",
        "# Parse out the top predicted label.\n",
        "def parseConfusionFiles(theFile):\n",
        "  for line in theFile:\n",
        "    value = line.strip(\"{}\")\n",
        "    values = value.split(\", '\")\n",
        "\n",
        "    # Get the review sentence.\n",
        "    sentence = values[0].split(\"'\")[-2]\n",
        "    sentences.append(sentence)\n",
        "\n",
        "    for item in values:\n",
        "      if item[:6] == \"labels\":\n",
        "        # Now the item we have looks something like \n",
        "        # labels': ['diversity and inclusion'\n",
        "        # Parse out the label\n",
        "        label = item.split(\"'\")[-2]\n",
        "        predictedLabels.append(label)\n",
        "    \n",
        "parseConfusionFiles(riotPos)\n",
        "parseConfusionFiles(riotNeg)\n",
        "parseConfusionFiles(sonyPos)\n",
        "parseConfusionFiles(sonyNeg)\n",
        "parseConfusionFiles(ubisoftPos)\n",
        "parseConfusionFiles(ubisoftNeg)\n",
        "parseConfusionFiles(activisionPos)\n",
        "parseConfusionFiles(activisionNeg)\n",
        "print(len(predictedLabels))\n",
        "print(len(sentences))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCr-csuZqz8i",
        "outputId": "67247aa9-4fa3-4d04-ca21-a902f549e7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to manually input values for each sentence as gold labels. We'll take in a number corresponding to the category, then store that category.\n",
        "\n",
        "'diversity and inclusion' = 1 \n",
        "\n",
        "'culture and values' = 2 \n",
        "\n",
        "'work life balance' = 3 \n",
        "\n",
        "'senior management' = 4\n",
        "\n",
        "'career opportunities' = 5 \n",
        "\n",
        "'compensation and benefits' = 6"
      ],
      "metadata": {
        "id": "YZ8TRTbCwBt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trueLabels = []\n",
        "\n",
        "# The user must be VERY careful to input a number between 1 and 6, or else they\n",
        "# will have to restart\n",
        "def getTrueLabels():\n",
        "  for i in range(len(predictedLabels)):\n",
        "    print(\"The sentence is \\\"\" + sentences[i] + \"\\\"\")\n",
        "    val = input(\"The true label is? \")\n",
        "    val = int(val)\n",
        "    \n",
        "    if val == 1:\n",
        "      trueLabels.append('diversity and inclusion')\n",
        "    elif val == 2:\n",
        "      trueLabels.append('culture and values')\n",
        "    elif val == 3:\n",
        "      trueLabels.append('work life balance')\n",
        "    elif val == 4:\n",
        "      trueLabels.append('senior management')\n",
        "    elif val == 5:\n",
        "      trueLabels.append('career opportunities')\n",
        "    elif val == 6:\n",
        "      trueLabels.append('compensation and benefits')\n",
        "    else: \n",
        "      print(\"ERROR: did not input [1, 6]. Please start over.\")\n",
        "\n",
        "\n",
        "getTrueLabels()"
      ],
      "metadata": {
        "id": "Z3bog0CHuEeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DAMAGE CONTROL: if you accidentally input an invalid character, you can uncomment this block\n",
        "# to get a smaller confusion matrix.\n",
        "# trueLabelsLength = len(trueLabels)\n",
        "# print(trueLabelsLength)\n",
        "# print(\"Predicted vs true\")\n",
        "# confusion_matrix(trueLabels, predictedLabels[:trueLabelsLength], labels = ['diversity and inclusion', 'culture and values', 'work life balance', 'senior management', 'career opportunities', 'compensation and benefits'])"
      ],
      "metadata": {
        "id": "SYjs0q1qCwKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll print the confusion matrix. We can interpret it like this:\n",
        "\n",
        "Example matrix: \n",
        "\n",
        "       [[0, 0, 0, 0, 0, 0],\n",
        "       [1, 0, 5, 0, 4, 3],\n",
        "       [0, 0, 3, 0, 2, 1],\n",
        "       [0, 0, 0, 0, 0, 0],\n",
        "       [0, 0, 0, 0, 1, 0],\n",
        "       [0, 0, 1, 0, 0, 4]]\n",
        "\n",
        "Let's look at line two. Remember our categories are `['diversity and inclusion', 'culture and values', 'work life balance', 'senior management', 'career opportunities', 'compensation and benefits']`. So line two\n",
        "\n",
        "`[1, 0, 5, 0, 4, 3]`\n",
        "\n",
        "can be interpreted as, \"of all the things that were actually related to culture and values, 1 was predicted by the model to be related to diversity, 0 were actually predicted to be related to culture, 5 were predicted to be related to work life balance, etc.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "apM5qSye6u75"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMX8oPKJb_VS",
        "outputId": "3bd7938e-7714-49ae-d79e-494d73a0e398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted vs true\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  0,  0,  0,  0],\n",
              "       [ 2, 26, 16,  1, 13,  3],\n",
              "       [ 0,  1, 21,  0,  4,  1],\n",
              "       [ 0,  6,  4,  4,  4,  0],\n",
              "       [ 1,  6,  5,  0, 18,  2],\n",
              "       [ 0,  6, 15,  1,  1, 23]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "print(\"Predicted vs true\")\n",
        "confusion_matrix(trueLabels, predictedLabels, labels = ['diversity and inclusion', 'culture and values', 'work life balance', 'senior management', 'career opportunities', 'compensation and benefits'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also use `sklearn`'s precision recall fscore support function to print these values per label. The output is four arrays of length `# of labels`: array 1 is precision, array 2 is recall, array 3 is fscore, and array 4 is support (in this case, the number of sentences that were gold labeled as belonging to each category).\n",
        "\n",
        "Precision = # of sentences that were actually `x` AND were labeled as `x` / # sentences labeled as `x`\n",
        "\n",
        "Recall = # of sentences that were labeled as `x` / # sentences that were actually `x` "
      ],
      "metadata": {
        "id": "RDHIX-sBElAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "-uuSikS_DP6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(trueLabels, predictedLabels[:185], average=None, labels=['diversity and inclusion', 'culture and values', 'work life balance', 'senior management', 'career opportunities', 'compensation and benefits'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w-NPRBkD3FJ",
        "outputId": "989f46b7-4e1c-4c8d-d467-b930e1d70324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.        , 0.56521739, 0.3442623 , 0.66666667, 0.45      ,\n",
              "        0.79310345]),\n",
              " array([0.        , 0.42622951, 0.77777778, 0.22222222, 0.5625    ,\n",
              "        0.5       ]),\n",
              " array([0.        , 0.48598131, 0.47727273, 0.33333333, 0.5       ,\n",
              "        0.61333333]),\n",
              " array([ 1, 61, 27, 18, 32, 46]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}