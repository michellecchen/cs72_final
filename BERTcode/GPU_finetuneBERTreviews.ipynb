{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltdW3RwQ65MU"
      },
      "source": [
        "# Finetuning a BERT to determine the valence of Glassdoor/Indeed reviews\n",
        "# CS72 Final, 22S\n",
        "## Written by Leah Ryu and Michelle Chen\n",
        "### leah.ryu.22@dartmouth.edu and michelle.chen.22@dartmouth.edu\n",
        "\n",
        "With a bunch of review sentences which have \"labels\" of positive and negative, classified according to topic, we can fine-tune a BERT model to label reviews as negative or positive. Then, once we have a nice accuracy, we can use this model to label reviews that lack gold labels. These reviews come from the 'content' field of the Indeed reviews, which is a general body of text without a specified valence.\n",
        "\n",
        "We owe great thanks to the HW6 Jupyter notebooks and the many BERT tutorials available online, including:\n",
        "\n",
        "https://www.geeksforgeeks.org/fine-tuning-bert-model-for-sentiment-analysis/#:~:text=Google%20created%20a%20transformer%2Dbased,dataset%20would%20lead%20to%20overfitting\n",
        "\n",
        "https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=sd1LiXGjZ420\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwgaUQXmN545"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0dyKVOBpk8d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import transformers as ppb\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "#for pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZTK73U3SU04"
      },
      "source": [
        "# Parsing the text files\n",
        "We need our text files parsed into one large dataframe with <\\<content\\>> and <\\<valence\\>> labels so that we can fine-tune our BERT with it. Let's take all the already-labeled data from each company â€” so, everything excluding the neutral data from Indeed. We can first use this data without worrying about topic categories or dates to fine-tune the BERT. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB7yT-ztvXjm",
        "outputId": "8de542ef-7356-4f06-df90-f7d9de42fb21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Libraries needed to import files from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49qwH-TP6yD3"
      },
      "outputs": [],
      "source": [
        "# Removing trailing whitespace from sentences (unneeded newlines, single-spaces, etc.)\n",
        "def remove_whitespace_from(review_sentences):\n",
        "  stripped_sentences = []\n",
        "  for sentence in review_sentences:\n",
        "    stripped_sentence = sentence.rstrip()\n",
        "    stripped_sentences.append(stripped_sentence)\n",
        "  return stripped_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFO0_344b2_A"
      },
      "outputs": [],
      "source": [
        "# Open all the files we need: pos and neg classification data\n",
        "# for the four companies, from Glassdoor and Indeed.\n",
        "\n",
        "# Riot reviews\n",
        "\n",
        "f1 = open(\"/content/drive/MyDrive/compling_final/Glassdoor/riotProsClassified.txt\", 'r')\n",
        "riotPos = remove_whitespace_from(f1.readlines())\n",
        "\n",
        "f2 = open(\"/content/drive/MyDrive/compling_final/Glassdoor/riotConsClassified.txt\", 'r')\n",
        "riotNeg = remove_whitespace_from(f2.readlines())\n",
        "\n",
        "f3 = open(\"/content/drive/MyDrive/compling_final/Indeed/riotProsIndeedClassified.txt\", 'r')\n",
        "riotIndeedPos = remove_whitespace_from(f3.readlines())\n",
        "\n",
        "f4 = open(\"/content/drive/MyDrive/compling_final/Indeed/riotConsIndeedClassified.txt\", 'r')\n",
        "riotIndeedNeg = remove_whitespace_from(f4.readlines())\n",
        "\n",
        "# Sony reviews\n",
        "\n",
        "f5 = open(\"/content/drive/MyDrive/compling_final/Glassdoor/sonyProsClassified.txt\", 'r')\n",
        "sonyPos = remove_whitespace_from(f5.readlines())\n",
        "\n",
        "f6 = open(\"/content/drive/MyDrive/compling_final/Glassdoor/sonyConsClassified.txt\", 'r')\n",
        "sonyNeg = remove_whitespace_from(f6.readlines())\n",
        "\n",
        "f7 = open(\"/content/drive/MyDrive/compling_final/Indeed/sonyProsIndeedClassified.txt\", 'r')\n",
        "sonyIndeedPos = remove_whitespace_from(f7.readlines())\n",
        "\n",
        "f8 = open(\"/content/drive/MyDrive/compling_final/Indeed/sonyConsIndeedClassified.txt\", 'r')\n",
        "sonyIndeedNeg = remove_whitespace_from(f8.readlines())\n",
        "\n",
        "# Ubisoft reviews\n",
        "\n",
        "f9 = open(\"/content/drive/MyDrive/compling_final/Glassdoor/ubisoftProsClassified.txt\", 'r')\n",
        "ubisoftPos = remove_whitespace_from(f9.readlines())\n",
        "\n",
        "f10 = open(\"/content/drive/MyDrive/compling_final/Glassdoor/ubisoftConsClassified.txt\", 'r')\n",
        "ubisoftNeg = remove_whitespace_from(f10.readlines())\n",
        "\n",
        "f11 = open(\"/content/drive/MyDrive/compling_final/Indeed/ubisoftProsIndeedClassified.txt\", 'r')\n",
        "ubisoftIndeedPos = remove_whitespace_from(f11.readlines())\n",
        "\n",
        "f12 = open(\"/content/drive/MyDrive/compling_final/Indeed/ubisoftConsIndeedClassified.txt\", 'r')\n",
        "ubisoftIndeedNeg = remove_whitespace_from(f12.readlines())\n",
        "\n",
        "# Activision reviews\n",
        "\n",
        "f13 = open(\"/content/drive/MyDrive/compling_final/Glassdoor/activisionProsClassified.txt\", 'r')\n",
        "activisionPos = remove_whitespace_from(f13.readlines())\n",
        "\n",
        "f14 = open(\"/content/drive/MyDrive/compling_final/Glassdoor/activisionConsClassified.txt\", 'r')\n",
        "activisionNeg = remove_whitespace_from(f14.readlines())\n",
        "\n",
        "f15 = open(\"/content/drive/MyDrive/compling_final/Indeed/activisionProsIndeedClassified.txt\", 'r')\n",
        "activisionIndeedPos = remove_whitespace_from(f15.readlines())\n",
        "\n",
        "f16 = open(\"/content/drive/MyDrive/compling_final/Indeed/activisionConsIndeedClassified.txt\", 'r')\n",
        "activisionIndeedNeg = remove_whitespace_from(f16.readlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CLGEOTpdmcr"
      },
      "outputs": [],
      "source": [
        "# We need to store all the data in one big dataframe with the correct labels.\n",
        "# https://cmdlinetips.com/2018/01/how-to-create-pandas-dataframe-from-multiple-lists/\n",
        "\n",
        "# As per the tutorial above, we'll make two long lists, then put them into a \n",
        "# dictionary and use that to make the dataframe\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# True = positive, False = negative\n",
        "def appendFilesToLabelsAndFeaturesList(valence, featuresList):\n",
        "  for i in range(len(featuresList)):\n",
        "    feature = featuresList[i].strip(\"\\n\")\n",
        "    if (feature != \"[LISTSEP]\"):\n",
        "      features.append(featuresList[i])\n",
        "      if (valence):\n",
        "        labels.append(1)\n",
        "      else:\n",
        "        labels.append(0)\n",
        "\n",
        "# Appending Riot reviews\n",
        "appendFilesToLabelsAndFeaturesList(True, riotPos)\n",
        "appendFilesToLabelsAndFeaturesList(False, riotNeg)\n",
        "appendFilesToLabelsAndFeaturesList(True, riotIndeedPos)\n",
        "appendFilesToLabelsAndFeaturesList(False, riotIndeedNeg)\n",
        "\n",
        "# Appending Sony reviews\n",
        "appendFilesToLabelsAndFeaturesList(True, sonyPos)\n",
        "appendFilesToLabelsAndFeaturesList(False, sonyNeg)\n",
        "appendFilesToLabelsAndFeaturesList(True, sonyIndeedPos)\n",
        "appendFilesToLabelsAndFeaturesList(False, sonyIndeedNeg)\n",
        "\n",
        "# Appending Ubisoft reviews\n",
        "appendFilesToLabelsAndFeaturesList(True, ubisoftPos)\n",
        "appendFilesToLabelsAndFeaturesList(False, ubisoftNeg)\n",
        "appendFilesToLabelsAndFeaturesList(True, ubisoftIndeedPos)\n",
        "appendFilesToLabelsAndFeaturesList(False, ubisoftIndeedNeg)\n",
        "\n",
        "# Appending Activision reviews\n",
        "appendFilesToLabelsAndFeaturesList(True, activisionPos)\n",
        "appendFilesToLabelsAndFeaturesList(False, activisionNeg)\n",
        "appendFilesToLabelsAndFeaturesList(True, activisionIndeedPos)\n",
        "appendFilesToLabelsAndFeaturesList(False, activisionIndeedNeg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHP6IZkfNLV-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "temp = list(zip(features, labels))\n",
        "random.shuffle(temp)\n",
        "features, labels = zip(*temp)\n",
        "features, labels = list(features), list(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2QpT2tLFsG9"
      },
      "outputs": [],
      "source": [
        "dictionary = {'features': features, 'labels': labels}\n",
        "df = pd.DataFrame(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kHh4Wdy7Mls"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNcHmddq7rnI"
      },
      "source": [
        "# BERT fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xq_QtkkTYwG"
      },
      "outputs": [],
      "source": [
        "# Import BERT-base pretrained model\n",
        "# https://huggingface.co/bert-base-uncased\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the fast BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80sdCCXGgXVP"
      },
      "source": [
        "Now that we have our dataframe sorted as two columns, one with features (in this case, our review sentences) and the second with labels (0 or 1 indicating negative or positive), we can go ahead and split up our data into training, validation, and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaITrVcUaOFb"
      },
      "outputs": [],
      "source": [
        "# We'll use the ratio .70: .15: .15, first splitting up into 0.7 and 0.3, then \n",
        "# splitting the 0.3 in half.\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['features'], df['labels'], \n",
        "                                                                    random_state=2021, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['labels'])\n",
        "\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2021, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7GEp3ZigrG_"
      },
      "source": [
        "Now we're going to tokenize the data and encode it into a format that BERT can read. Under the hood, tokenization is the separation of sentences into their tokens (which look a lot like words but are often more granular) and the addition of the `[CLS]` and `[SEP]` tokens at the beginning and end of the sequence. Then, encoding means transforming tokens into their `input_ids`, which are integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQPjK4vZVwNZ"
      },
      "outputs": [],
      "source": [
        "tokenizedTrain = train_text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenizedVal = val_text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenizedTest = test_text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AytR6y8Fh3ED"
      },
      "source": [
        "Now we have a number of encoded token vectors of varying lengths. We need to pad them all to the length so that we can represent all the vectors as a singular 2D array and have them processed as a batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O29cSy73V8Ud"
      },
      "outputs": [],
      "source": [
        "# Given a list of token sequences, this returns the length of the longest sequence.\n",
        "def determineMaxLength(tokenized):\n",
        "  max_len = 0\n",
        "  for i in tokenized.values:\n",
        "      if len(i) > max_len:\n",
        "          max_len = len(i)\n",
        "  return max_len\n",
        "\n",
        "maxLenTrain = determineMaxLength(tokenizedTrain)\n",
        "maxLenVal = determineMaxLength(tokenizedVal)\n",
        "maxLenTest = determineMaxLength(tokenizedTest)\n",
        "\n",
        "# We'll take the longest out of all the sequences data sets and use that to determine\n",
        "# how much we should pad each sequence.\n",
        "max_len = max(maxLenTrain, maxLenVal, maxLenTest)\n",
        "\n",
        "paddedTrain = np.array([i + [0]*(max_len-len(i)) for i in tokenizedTrain.values])\n",
        "paddedVal = np.array([i + [0]*(max_len-len(i)) for i in tokenizedVal.values])\n",
        "paddedTest = np.array([i + [0]*(max_len-len(i)) for i in tokenizedTest.values])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78KyzHK9fpuO",
        "outputId": "99b98c50-d550-4e15-e865-95f5b37e9bee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8610, 222)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# As a sanity check, we can look at the shape of our training data array\n",
        "np.array(paddedTrain).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NWxazRIWUfG"
      },
      "outputs": [],
      "source": [
        "features = df['features']\n",
        "labels = df['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FpxCitor_S8"
      },
      "outputs": [],
      "source": [
        "def labelsObjectToList(labels):\n",
        "  labelsList = []\n",
        "  for label in labels:\n",
        "    labelsList.append(int(label))\n",
        "  return labelsList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5s4539_bR-s"
      },
      "outputs": [],
      "source": [
        "# We convert all this tokenized data into a form that PyTorch can use.\n",
        "train_seq = torch.tensor(paddedTrain)\n",
        "train_mask = torch.tensor(np.where(paddedTrain != 0, 1, 0))\n",
        "train_y = torch.tensor(labelsObjectToList(train_labels))\n",
        "\n",
        "val_seq = torch.tensor(paddedVal)\n",
        "val_mask = torch.tensor(np.where(paddedVal != 0, 1, 0))\n",
        "val_y = torch.tensor(labelsObjectToList(val_labels))\n",
        "\n",
        "test_seq = torch.tensor(paddedTest)\n",
        "test_mask = torch.tensor(np.where(paddedTest != 0, 1, 0))\n",
        "test_y = torch.tensor(labelsObjectToList(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6_S4wsasa_k"
      },
      "source": [
        "# IMPORTANT NOTE \n",
        "After this point until the next note, the code is DIRECTLY taken from \n",
        "https://github.com/Himabindugssn/Sentiment-classification-using-transformers with little to no modification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNgSbTXiscnr"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# define a batch size\n",
        "batch_size = 64\n",
        "# num_workers = 1\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to make sure to freeze the already existing layers of the BERT so that we don't go about retraining the whole thing."
      ],
      "metadata": {
        "id": "YAGrTuWVZbq4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkMJElA6sjWl"
      },
      "outputs": [],
      "source": [
        "# freeze the BERT architecture\n",
        "\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll custom define our BERT architecture with parameters such as model, activation functions, and forward pass instructions."
      ],
      "metadata": {
        "id": "kKhdP5nZZh8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG8uCBs4so_K"
      },
      "outputs": [],
      "source": [
        "class BERT_architecture(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_architecture, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.2)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ4Z4BNvstkL"
      },
      "outputs": [],
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_architecture(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjtXSBxgswLa"
      },
      "outputs": [],
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = 1e-5)  # learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we're bound to have more of one label than of the other, we'll weight them to compensate for the imbalance of data."
      ],
      "metadata": {
        "id": "GdJtDhylZuRd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOGLWE3rsy77",
        "outputId": "57305209-5301-4e84-cee0-2fce0ec8ccf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class weights are [1.08849558 0.92481203] for [0 1]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight(class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_labels),\n",
        "                                        y = train_labels \n",
        "                                     )\n",
        "print(\"class weights are {} for {}\".format(class_weights,np.unique(train_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRdMvAZus1jK",
        "outputId": "d963f75e-e8b9-422a-dd72-3abba943fd8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4655\n",
              "0    3955\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#count of both the categories of training labels\n",
        "pd.value_counts(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSN6h6cvs4F1"
      },
      "outputs": [],
      "source": [
        "#wrap class weights in tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push weights to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define loss function\n",
        "# add weights to handle the \"imbalance\" in the dataset\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAxVJGdvs7zw"
      },
      "outputs": [],
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "katgYKm3tCYg"
      },
      "outputs": [],
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C85jTtbXtE8S"
      },
      "outputs": [],
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _  = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print('\\nTraining Loss: {}'.format(train_loss))\n",
        "    print('Validation Loss: {}'.format(valid_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6VNU0b5Pk9C"
      },
      "source": [
        "## BREAK - PLEASE DO NOT RUN ANY CELLS AFTER THIS POINT UNTIL `saved_weights.pt` IS SAFELY STORED IN DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebu2VokbtHWA",
        "outputId": "c4eb3d82-f005-4592-9424-0286c1a2423e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#load weights of best model\n",
        "# If loading right after training in this file, use option 1. Else, use option 2\n",
        "# to load a model from Drive.\n",
        "path = 'saved_weights.pt'                                                # 1\n",
        "# path = 'drive/MyDrive/compling_final/saved_weights_12EpochfullData.pt'     # 2\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6GDXQLbr7tL"
      },
      "outputs": [],
      "source": [
        "# Please run this cell if and only if the next one throws an error saying that the\n",
        "# CUDA is out of memory.\n",
        "\n",
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWnJrL_btJif"
      },
      "outputs": [],
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq[:200].to(device), test_mask[:200].to(device))\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  \n",
        "  preds2 = model(test_seq[200:400].to(device), test_mask[200:400].to(device))\n",
        "  preds2 = preds2.detach().cpu().numpy()\n",
        "\n",
        "  preds3 = model(test_seq[400:600].to(device), test_mask[400:600].to(device))\n",
        "  preds3 = preds3.detach().cpu().numpy()\n",
        "\n",
        "  preds4 = model(test_seq[600:800].to(device), test_mask[600:800].to(device))\n",
        "  preds4 = preds4.detach().cpu().numpy()\n",
        "\n",
        "  preds5 = model(test_seq[800:1000].to(device), test_mask[800:1000].to(device))\n",
        "  preds5 = preds5.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUT5z25ttOxO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6ngGmhRtQ_G",
        "outputId": "208d7bac-e266-41fa-ff34-f1f9bc7c4528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.78      0.79       458\n",
            "           1       0.82      0.84      0.83       542\n",
            "\n",
            "    accuracy                           0.81      1000\n",
            "   macro avg       0.81      0.81      0.81      1000\n",
            "weighted avg       0.81      0.81      0.81      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "newPreds = np.concatenate((preds, preds2, preds3, preds4, preds5))\n",
        "pred = np.argmax(newPreds, axis = 1)\n",
        "print(classification_report(test_y[:1000], pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the BERT to determine the valence of neutral/unlabeled Indeed data\n",
        "\n",
        "<sub>From this point onward, the code is once again written by us. Please contact leah.ryu.22@dartmouth.edu with any questions about this section.</sub>\n",
        "\n",
        "Now that we've trained our BERT and are satisfied with its performance, we'll use it to classify our unlabeled data from the Indeed general review corps. \n",
        "\n",
        "Since the output we're using is simply a series of predicted labels with no indication of review date or the sentences that were labeled as such, we need to pre-separate our data into bins corresponding to date ranges and topics to be run through the BERT. We'll try to automate this process as much as possible, then write bin pos/neg counts to files for each company for each topic. \n"
      ],
      "metadata": {
        "id": "QzXLux4QBH5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "def predictionsForDataset(test_seq, test_mask):\n",
        "  with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "\n",
        "  return np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "Jh8T8lzwBIyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve prediction counts from classification report\n",
        "def countPredictedLabels(pred):\n",
        "  pos = 0\n",
        "  neg = 0\n",
        "  for integer in pred:\n",
        "    if integer == 0:\n",
        "      neg += 1\n",
        "    else:\n",
        "      pos += 1\n",
        "  return pos, neg"
      ],
      "metadata": {
        "id": "RW7JzCniBRKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sequence and an attention mask for a list of features\n",
        "def createSequenceAndMask(features):\n",
        "  features = pd.DataFrame(features)[0]\n",
        "  print(features)\n",
        "\n",
        " \n",
        "  tokenizedFeatures = features.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "  max_len = determineMaxLength(tokenizedFeatures)\n",
        "  padded = np.array([i + [0]*(max_len-len(i)) for i in tokenizedFeatures.values])\n",
        "\n",
        "  seq = torch.tensor(padded)\n",
        "  mask = torch.tensor(np.where(padded != 0, 1, 0))\n",
        "\n",
        "  seq = seq.type(torch.LongTensor)\n",
        "  mask = mask.type(torch.LongTensor)\n",
        "\n",
        "  # https://github.com/huggingface/transformers/issues/2952\n",
        "  return seq, mask"
      ],
      "metadata": {
        "id": "HVsR8O1dBTsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# https://stackoverflow.com/questions/35147063/python-sort-lists-from-1-list-based-on-date-elements\n",
        "# Sort a list of sentences and a list of dates in ascending order based on the dates.\n",
        "def zipAndSortByDate(datesList, sentsList):\n",
        "  if len(datesList) > 0:\n",
        "    temp1, temp2 = zip(*sorted(zip(datesList, sentsList), key=lambda x: datetime.datetime.strptime(x[0], \"%m/%d/%Y\")))\n",
        "    temp1, temp2 = list(temp1), list(temp2)\n",
        "    return temp1, temp2\n",
        "  else:\n",
        "    return [], []"
      ],
      "metadata": {
        "id": "3xlkiwWmBVx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output: one file, separated into six sections (one for each topic) using the token [LISTSEP]\n",
        "# The format of the file looks something like this:\n",
        "#      04/2015:6|7\n",
        "#      06/2016:8|9\n",
        "#      [LISTSEP]\n",
        "#      07/2012:1|2\n",
        "#      [LISTSEP]\n",
        "#      . . .\n",
        "#      07/2018:0|3\n",
        "#      [LISTSEP]\n",
        "# For example, line 1 means that for the month of April 2015, there were 6 positive\n",
        "# and 7 negative reviews written on the topic of diversity and inclusion.\n",
        "def writeMonthlyValencesToFile(allSentences, allDates, fileName):\n",
        "  f1 = open(fileName, 'w')\n",
        "\n",
        "  # Six topics\n",
        "  sortedDates = [[],[],[],[],[],[]]\n",
        "  sortedSentences = [[],[],[],[],[],[]]\n",
        "\n",
        "  # Start on first topic list\n",
        "  listIndex = 0\n",
        "  for i in range(len(allSentences)):\n",
        "    if allSentences[i] == \"[LISTSEP]\\n\" or allSentences[i] == \"[LISTSEP]\":\n",
        "      listIndex += 1\n",
        "      continue\n",
        "    else:\n",
        "      # add the sentence and date to the appropriate list in the large list\n",
        "      sortedDates[listIndex].append(allDates[i])\n",
        "      sortedSentences[listIndex].append(allSentences[i])\n",
        "     \n",
        "  # Sort every list inside the list of lists according to date.\n",
        "  # Then, write that into monthly bins in a file, with [LISTSEP] separating topics.\n",
        "  for i in range(6):\n",
        "    sortedDates[i], sortedSentences[i] = zipAndSortByDate(sortedDates[i], sortedSentences[i]) \n",
        "    \n",
        "    dts = sortedDates[i]\n",
        "    snts = sortedSentences[i]\n",
        "\n",
        "    # For each month bin, pass the month's features through the BERT. Count up\n",
        "    # the number of positives and negatives and write it into a line in the file.\n",
        "    currentMonthFeatures = []\n",
        "\n",
        "    # Only do this if there are actually dates in the topic.\n",
        "    if len(dts) > 0:\n",
        "\n",
        "      # Establish the first bin with the first year/month in the list.\n",
        "      currentMonth = dts[0].split(\"/\")[0]\n",
        "      currentYear = dts[0].split(\"/\")[2]\n",
        "      currentMonthFeatures.append(snts[0])\n",
        "\n",
        "      # Go through each date in dates for this topic, putting the counts into one\n",
        "      # bin per month. This means we'll establish and run some data through BERT\n",
        "      # every time we hit a new month bin.\n",
        "      for index in range(1, len(dts)):\n",
        "        dateSplit = dts[index].split(\"/\")\n",
        "        month = dateSplit[0]\n",
        "        year = dateSplit[2]\n",
        "\n",
        "        feature = snts[index]\n",
        "\n",
        "        if month == currentMonth and year == currentYear:\n",
        "          currentMonthFeatures.append(feature)\n",
        "        else:\n",
        "          # The month changed, so write to the file\n",
        "          if len(currentMonthFeatures) > 0:\n",
        "            print(currentMonthFeatures)\n",
        "            lineString = currentMonth + \"/\" + currentYear + \":\" \n",
        "            f1.write(lineString)\n",
        "            test, mask = createSequenceAndMask(currentMonthFeatures)\n",
        "            posCount, negCount = countPredictedLabels(predictionsForDataset(test, mask))\n",
        "            f1.write(str(posCount))\n",
        "            f1.write(\"|\")\n",
        "            f1.write(str(negCount))\n",
        "            f1.write(\"\\n\")\n",
        "          currentMonth = month\n",
        "          currentYear = year\n",
        "          currentMonthFeatures = []\n",
        "          currentMonthFeatures.append(feature)\n",
        "\n",
        "    # Next topic for this company.\n",
        "    f1.write(\"[LISTSEP]\\n\")\n"
      ],
      "metadata": {
        "id": "zKx7k00MBYWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries needed to import files from drive: run if you haven't up above \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcPk-czrBsLF",
        "outputId": "7ead03f9-8f6a-478c-a69d-722e06f71d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences = [\"place111\", \"place112\", \"place113\", \"place114\", \"place115\", \"[LISTSEP]\", \"[LISTSEP]\", \"place5\", \"place6\", \"[LISTSEP]\", \"place7\", \"place8\", \"[LISTSEP]\", \"place9\", \"place10\", \"[LISTSEP]\", \"place11\", \"place12\", \"[LISTSEP]\"]\n",
        "# dates = [\"05/06/2015\", \"05/04/2015\", \"03/02/2006\", \"07/08/2006\", \"09/15/2021\", \"[LISTSEP]\", \"[LISTSEP]\", \"04/03/2016\", \"02/02/2012\", \"[LISTSEP]\", \"04/03/2016\", \"02/02/2012\", \"[LISTSEP]\", \"04/03/2016\", \"02/02/2012\", \"[LISTSEP]\", \"04/03/2016\", \"02/02/2012\", \"[LISTSEP]\"]\n",
        "# writeMonthlyValencesToFile(sentences, dates, \"riot\")"
      ],
      "metadata": {
        "id": "8keLLD7lBxML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need one file for each company.\n",
        "# Make sure to run remove_whitespaces_from() above.\n",
        "\n",
        "# Riot\n",
        "riotFile = open(\"/content/drive/MyDrive/compling_final/Indeed/riotNeutralsIndeedClassified.txt\", 'r')\n",
        "riotSentences = remove_whitespace_from(riotFile.readlines())\n",
        "\n",
        "riotDatesFile = open(\"/content/drive/MyDrive/compling_final/Indeed/dates/riotNeutralsIndeedDates.txt\", 'r')\n",
        "riotDates = remove_whitespace_from(riotDatesFile.readlines())\n",
        "\n",
        "# Activision\n",
        "actFile = open(\"/content/drive/MyDrive/compling_final/Indeed/activisionNeutralsIndeedClassified.txt\", 'r')\n",
        "actSentences = remove_whitespace_from(actFile.readlines())\n",
        "\n",
        "actDatesFile = open(\"/content/drive/MyDrive/compling_final/Indeed/dates/activisionNeutralsIndeedDates.txt\", 'r')\n",
        "actDates = remove_whitespace_from(actDatesFile.readlines())\n",
        "\n",
        "# Sony\n",
        "sonyFile = open(\"/content/drive/MyDrive/compling_final/Indeed/sonyNeutralsIndeedClassified.txt\", 'r')\n",
        "sonySentences = remove_whitespace_from(sonyFile.readlines())\n",
        "\n",
        "sonyDatesFile = open(\"/content/drive/MyDrive/compling_final/Indeed/dates/sonyNeutralsIndeedDates.txt\", 'r')\n",
        "sonyDates = remove_whitespace_from(sonyDatesFile.readlines())\n",
        "\n",
        "# Ubisoft\n",
        "ubiFile = open(\"/content/drive/MyDrive/compling_final/Indeed/ubisoftNeutralsIndeedClassified.txt\", 'r')\n",
        "ubiSentences = remove_whitespace_from(ubiFile.readlines())\n",
        "\n",
        "ubiDatesFile = open(\"/content/drive/MyDrive/compling_final/Indeed/dates/ubisoftNeutralsIndeedDates.txt\", 'r')\n",
        "ubiDates = remove_whitespace_from(ubiDatesFile.readlines())\n"
      ],
      "metadata": {
        "id": "ueToNx-RB_yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writeMonthlyValencesToFile(riotSentences, riotDates, '/content/drive/MyDrive/compling_final/riotIndeedValences.txt')\n",
        "writeMonthlyValencesToFile(actSentences, actDates, '/content/drive/MyDrive/compling_final/activisionIndeedValences.txt')\n",
        "writeMonthlyValencesToFile(sonySentences, sonyDates, '/content/drive/MyDrive/compling_final/sonyIndeedValences.txt')\n",
        "writeMonthlyValencesToFile(ubiSentences, ubiDates, '/content/drive/MyDrive/compling_final/ubisoftIndeedValences.txt')"
      ],
      "metadata": {
        "id": "SBOWORH_Evud"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GPU_finetuneBERTreviews.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}